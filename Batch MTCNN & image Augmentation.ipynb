{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about this working page\n",
    "This page is a working notebook were it was edited according to the requirements. This was used mainly for dataset creation and based on Pytorch <br>\n",
    "We batch extracted faces using batch MTCNN. In addition this page was used for batch augmentation for creating our dataset. <br>\n",
    "Please note that after the dataset creation we shifted to TensorFlow instead of Pytorch. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code inspired from the following website\n",
    "https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch\n",
    "https://machinelearningmastery.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group photo Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create face detector\n",
    "detector = MTCNN(image_size=182, margin=20, keep_all=True, post_process=False)\n",
    "\n",
    "# Load a single image and display\n",
    "v_cap = cv2.VideoCapture('../coursework/images/raw/78/IMG_6990.jpg')\n",
    "success, frame = v_cap.read()\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame = Image.fromarray(frame)\n",
    "#frame = frame.rotate(275)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.imshow(frame)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Detect face\n",
    "faces = detector(frame)\n",
    "print('Face Detected ...')\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, len(faces))\n",
    "for face, ax in zip(faces, axes):\n",
    "    ax.imshow(face.permute(1, 2, 0).int().numpy())\n",
    "    ax.axis('off')\n",
    "fig.show()\n",
    "\n",
    "#save_paths = [f'../coursework/images/processed/78/image300_{i}.jpg' for i in range(100,200)]\n",
    "#detector(frame, save_path=save_paths);\n",
    "#print('Image Saved ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN(image_size=182, margin=20, select_largest=False, post_process=False)\n",
    "\n",
    "# Load a vide8\n",
    "v_cap = cv2.VideoCapture('../coursework/images/Class/jpeg/IMG_6819.jpg')\n",
    "v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Loop through video\n",
    "batch_size = 58\n",
    "frames = []\n",
    "boxes = []\n",
    "landmarks = []\n",
    "view_frames = []\n",
    "view_boxes = []\n",
    "view_landmarks = []\n",
    "for _ in tqdm(range(v_len)):\n",
    "    \n",
    "    # Load frame\n",
    "    success, frame = v_cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "        \n",
    "    # Add to batch, resizing for speed\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = frame.resize([int(f * 0.25) for f in frame.size])\n",
    "    frames.append(frame)\n",
    "    \n",
    "    # When batch is full, detect faces and reset batch list\n",
    "    \n",
    "    if len(frames) >= batch_size:\n",
    "        batch_boxes, _, batch_landmarks = detector.detect(frames, landmarks=True)\n",
    "        boxes.extend(batch_boxes)\n",
    "        landmarks.extend(batch_landmarks)\n",
    "        \n",
    "        view_frames.append(frames[-1])\n",
    "        view_boxes.append(boxes[-1])\n",
    "        view_landmarks.append(landmarks[-1])\n",
    "        \n",
    "        frames = []\n",
    "\n",
    "save_paths = [f'../coursework/images/processed/78/image1000_{i}.jpg' for i in range(len(frames))]\n",
    "detector(frames, save_path=save_paths);\n",
    "print('Image Saved')\n",
    "\n",
    "#Visualize\n",
    "fig, ax = plt.subplots(2, 2, figsize=(18, 12))\n",
    "for i in range(4):\n",
    "    ax[int(i / 2), i % 2].imshow(view_frames[i])\n",
    "    ax[int(i / 2), i % 2].axis('off')\n",
    "    for box, landmark in zip(view_boxes[i], view_landmarks[i]):\n",
    "        ax[int(i / 2), i % 2].scatter(*np.meshgrid(box[[0, 2]], box[[1, 3]]), s=8)\n",
    "        ax[int(i / 2), i % 2].scatter(landmark[:, 0], landmark[:, 1], s=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io, exposure, img_as_ubyte\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_flip(image):\n",
    "    return np.flipud(image)\n",
    "\n",
    "def h_flip(image):\n",
    "    return  np.fliplr(image)\n",
    "\n",
    "def add_noise(image):\n",
    "    return random_noise(image)\n",
    "\n",
    "def blur(image):\n",
    "    return cv2.GaussianBlur(image, (9,9),0)\n",
    "\n",
    "def gamma(image, gamma=0.5):\n",
    "    return exposure.adjust_gamma(image, gamma) \n",
    "\n",
    "def anticlockwise_rotation(image):\n",
    "    angle= random.randint(0,180)\n",
    "    return rotate(image, angle)\n",
    "\n",
    "def clockwise_rotation(image):\n",
    "    angle= random.randint(0,180)\n",
    "    return rotate(image, -angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augmentation = { 'Horizontal Flip': h_flip, \n",
    "                    'Vertical Flip': v_flip,\n",
    "                    'Noise': add_noise,\n",
    "                    'Gamma': gamma } \n",
    "\n",
    "# Raw & augmented images paths\n",
    "rawPath=\"C:/Users/Tareq/Desktop/vision/coursework/images/processed/unknown 3\"\n",
    "augmentedPath=\"C:/Users/Tareq/Desktop/vision/coursework/images/processed/unknown 3\" \n",
    "\n",
    "images=[] \n",
    "\n",
    "# Append to images array     \n",
    "for im in os.listdir(rawPath):  \n",
    "    images.append(os.path.join(rawPath,im))\n",
    "\n",
    "# Number of images needed\n",
    "images_to_generate=80  \n",
    "\n",
    "i=1                       \n",
    "\n",
    "while i<=images_to_generate:    \n",
    "    image=random.choice(images)\n",
    "    original_image = io.imread(image)\n",
    "    augmented=None\n",
    "\n",
    "    n = 0      \n",
    "    count = random.randint(1, len(Augmentation)) #choose random number of transformation to apply on the image\n",
    "    \n",
    "    # Random Functions to augment\n",
    "    while n <= count:\n",
    "        key = random.choice(list(Augmentation))\n",
    "        augmented = Augmentation[key](original_image)\n",
    "        n = n + 1\n",
    "        \n",
    "    new_image_path= \"%s/augmented_image_%s.jpg\" %(augmentedPath, i)\n",
    "    augmented = img_as_ubyte(augmented)\n",
    "    \n",
    "    # RGB conversion before saving\n",
    "    augmented=cv2.cvtColor(augmented, cv2.COLOR_BGR2RGB) \n",
    "    cv2.imwrite(new_image_path, augmented) \n",
    "    i =i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
